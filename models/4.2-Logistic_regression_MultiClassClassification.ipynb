{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3786c95d-4575-4933-baa6-9fece81380af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "511dbdf6-9638-4b5b-a15e-8d1199da2dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(logistic_regression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat\n",
    "    \n",
    "    def predict(self, X):\n",
    "        lin = self.forward(X)\n",
    "        # softmaxFn = nn.Softmax(dim=1)\n",
    "        # output = softmaxFn(input)\n",
    "        _, pos = torch.max(lin, dim=1) # returning the position of the max value which will be the class\n",
    "        return pos\n",
    "    \n",
    "    def accuracy(self, x_test, y_test):\n",
    "        y_pred = self.predict(x_test)\n",
    "        return torch.mean((y_pred == y_test.type(torch.ByteTensor)).type(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26f0d4b-5642-472b-abf1-a04496e9b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad5ab062-c700-4b98-ba4c-3f85cfed96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "_x = iris.data\n",
    "_y = iris.target\n",
    "\n",
    "# stacking the new data together to use it for shuffling later\n",
    "data = np.column_stack((_x, _y))\n",
    "shufled_data = shuffle(data)\n",
    "\n",
    "# new data after shuffling\n",
    "x = shufled_data[:, 0:4]\n",
    "y = shufled_data[:, 4]\n",
    "\n",
    "# convert to tensors\n",
    "X = torch.from_numpy(x.astype(np.float32))\n",
    "Y = torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d29a18e-c0a6-4144-90e6-55e9e414f24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([105, 4])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "n_samples, n_features = X_train.shape\n",
    "\n",
    "# setting up the model \n",
    "model = logistic_regression(n_features, 3)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcbb2b81-bc10-449d-9b43-d0da725ab448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1000], Loss: 0.1378\n",
      "Epoch [100/1000], Loss: 0.1326\n",
      "Epoch [200/1000], Loss: 0.1281\n",
      "Epoch [300/1000], Loss: 0.1243\n",
      "Epoch [400/1000], Loss: 0.1209\n",
      "Epoch [500/1000], Loss: 0.1179\n",
      "Epoch [600/1000], Loss: 0.1152\n",
      "Epoch [700/1000], Loss: 0.1128\n",
      "Epoch [800/1000], Loss: 0.1106\n",
      "Epoch [900/1000], Loss: 0.1086\n",
      "predictions:  tensor([1, 1, 0, 2, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 0, 1, 2, 1, 2,\n",
      "        2, 1, 1, 2, 2, 0, 1, 0, 0, 1, 0, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1])\n",
      "Y_test:  tensor([1., 1., 0., 2., 0., 1., 2., 0., 2., 0., 0., 0., 0., 0., 2., 1., 2., 2.,\n",
      "        0., 0., 1., 2., 1., 2., 2., 1., 1., 2., 2., 0., 1., 0., 0., 1., 0., 2.,\n",
      "        2., 2., 2., 2., 0., 0., 1., 1., 1.])\n",
      "accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "def train_model(epochs, X, Y):    \n",
    "    for epoch in range(epochs):\n",
    "        yhat = model(X)\n",
    "        loss = criterion(yhat, Y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "Y_train = Y_train.long()\n",
    "train_model(num_epochs, X_train, Y_train)\n",
    "\n",
    "# print(type(X_test))\n",
    "with torch.no_grad():\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"predictions: \", predictions)\n",
    "    \n",
    "    # Calculate accuracy \n",
    "    # Y_test = torch.argmax(Y_train, dim=1)\n",
    "    print(\"Y_test: \", Y_test)\n",
    "    acc = model.accuracy(X_test, Y_test)  \n",
    "    print(f'accuracy: {acc.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2318a955-2b7b-4ea7-92d5-809222c6e794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKLEARN MODEL\n",
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"SKLEARN MODEL\")\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
