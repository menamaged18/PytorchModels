{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68072a1-dbdb-42d5-8292-0ab01a192f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b030dd-0ee3-43f1-b3d8-559e5e67d0f4",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d51646ba-4863-4ed8-a4c1-29593e5a1115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:03<00:00, 2894350.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 225205.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1453341.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4545580.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d998015d-67bb-406d-ab76-b11aff63e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b70653b4-16ab-4a39-aadb-f197aa8733a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "img_shape = image.shape\n",
    "flattened_image = image.view(-1)\n",
    "print(len(image))\n",
    "print(len(flattened_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed23182-da18-4bfe-a810-b0c57c75d422",
   "metadata": {},
   "source": [
    "### Neural Network with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fd4ad869-52e5-4abc-bf22-38d715b89932",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    \n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(NN, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))  \n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "    def train(self, model, train_data, criterion, optimizer, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            i = 0\n",
    "            for i, (x, y) in enumerate(train_loader): \n",
    "                optimizer.zero_grad()\n",
    "                z = model(x.view(x.size(0), -1))\n",
    "                loss = criterion(z, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def val_acc(self, model, val_data):\n",
    "        correct = 0\n",
    "        for x, y in val_data:\n",
    "            z = model(x.view(x.size(0), -1))\n",
    "            _, label = torch.max(z, 1)\n",
    "            correct += (label == y).sum().item()\n",
    "        return 100 * (correct / len(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c7fc7b89-2d6c-4eb3-940d-ba18bbb750fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(flattened_image)\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model1 = NN(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model1.parameters(), lr=learning_rate)\n",
    "model1.train(model1, train_loader, criterion, optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb4212cf-769c-43a7-8cb5-9f1d310b7853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.150000000000006\n"
     ]
    }
   ],
   "source": [
    "print(model1.val_acc(model1, validation_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90222bda-f596-4a9a-916a-7362cd137c81",
   "metadata": {},
   "source": [
    "### improve my model for more accuracy and use gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e8380380-aab9-4908-9553-d57d0c78d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "abdf3bc7-3164-4d43-af8c-0def3c2da23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check if gpu works\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "da35fede-38ec-4092-8fce-8c729000ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNGPU(nn.Module):\n",
    "    \n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(NNGPU, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.relu = nn.ReLU()  \n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.linear2(x)  \n",
    "        return x\n",
    "\n",
    "    def train(self, train_data, criterion, optimizer, epochs=100):\n",
    "        self.to(device)  \n",
    "        for epoch in range(epochs):\n",
    "            for i, (x, y) in enumerate(train_data): \n",
    "                x, y = x.to(device), y.to(device)  \n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                z = self.forward(x.view(x.size(0), -1))\n",
    "                loss = criterion(z, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def val_acc(self, val_data):\n",
    "        self.to(device)  \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_data:\n",
    "                x, y = x.to(device), y.to(device)  \n",
    "                z = self.forward(x.view(x.size(0), -1))\n",
    "                _, predicted = torch.max(z.data, 1)\n",
    "                total += y.size(0)\n",
    "                correct += (predicted == y).sum().item()\n",
    "        return 100 * (correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2a17a3f5-91f8-4438-88d4-129d399375a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(flattened_image)\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model2 = NNGPU(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=learning_rate)\n",
    "model2.train(train_loader, criterion, optimizer2, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4e6b1248-eed6-4fb2-b54c-6fba932e5771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.92999999999999\n"
     ]
    }
   ],
   "source": [
    "print(model2.val_acc(validation_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a532b6-dc10-4cab-9299-0f557dafa2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
